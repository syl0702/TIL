# Machine Learning 수학 요약
## 스칼라 벡터
1. 집합은 순서가 없다 = 순번이 없다 = 인덱스 없다.
    - 집합에서의 아래 첨자는 인덱스가 아니라 아이디. 고유값.
        - x들을 구별해야 해서.
2. 실수 집합 R
    - 이 세상에 존재하는 모든 실수들에 대한 집합
    - (x1, x2) 숫자 쌍(세트) E R*R로 표현.
    - 보통 제곱으로 사용한다.

3. 데이터: 수집된 값 (이를 모으면 정보가 된다.)
    - 스칼라: 타겟 1개, 종류 1개
    - 벡터
        - 타겟:N개 종류: 1개
        - 타겟: 1개 종류: N개

        - 특징 벡터(Feature Vector)
            - 데이터 벡터가 예측 문제에서 입력 Data로 사용하는 것.
            - X-> Y 할 때 오차를 작게 하는 "학습"을 시킨다.

4. 행렬: 타겟 N개, 종류 M개
    - 행렬을 배열로 표현해.

5. Tensor: 3차원
    - 스칼라: 0-Rank T
    - 벡터: 1-Rank T
    - 행렬: 2-Rank T
6. 전치 행렬
7. 대각 행렬
8. 항등 행렬- 대각 선분이 1
9. 대칭 행렬은 정방 행렬만 가능하다.

10. 덧셈과 곱셈을 하는 이유는 Data의 요약을 위한 것.
    - 덧셈은 주로 서로 연관성이 없는 데이터를 요약할 때, 곱셈은 주로 연관성이 있는 데이터를 요약할 때 사용한다.

## 선형 회귀
1. 선형 회귀 식에서 w는 데이터를 강조하는 부분으로 가중치라고도 한다.
2. 이러한 가중치가 높을 경우 x가 조금만 높아져도 급격히 올라간다.
3. 즉, x 값을 어떻게 반영할 것인가를 보여주는 것.

## 선형 조합
- 벡터/행렬에 스칼라값을 곱한 후 더하거나 뺀 것을 벡터/행렬의 선형 조합(linear Combination)이라고 함.


## 잔차
1. 잔차는 error 즉 오차를 줄이기 위한 것.

## 잔차 제곱합
- 잔차 제곱합을 구하는 이유는 **음수를 없애기 위해서**이다.
- 오차 관리는 하나로 해야 하기 때문에 오차들을 다 더해야 한다.
- 잔차가 음수 항목으로 인하여 합이 0이 되는 것을 막기 위해 제곱이 아닌 절댓값을 사용할 수도 있으나, 오차를 쉽게 고치기가 어렵다.
- 그러나 제곱합을 할 경우, 오차가 났을 때 그 숫자가 엄청나게 올라가기 때문에 오차를 수월하게 고칠 수 있다.